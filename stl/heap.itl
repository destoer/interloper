
struct HeapNode
{
    next : HeapNode@;

    // NOTE: inclusive Node
    blocks : u64;
}

struct Heap
{
    free_list : HeapNode@ = NULL;

    // NOTE: this is in block counts
    used : u64;
    capacity : u64;
}


constant HEAP_DEFAULT_BLOCK_COUNT : u32 = 1024;
constant HEAP_BLOCK_SIZE : u32 = HeapNode.size;
constant HEAP_DEFAULT_ALLOC_SIZE : u32 = HEAP_BLOCK_SIZE * HEAP_DEFAULT_BLOCK_COUNT;

func usable_blocks(heap: const Heap@) u64
{
    return (heap.capacity - heap.used);
}

func heap_usage(heap: const Heap@)
{
    print("heap usage:\n");
    print("used: {}\n",heap.used * HEAP_BLOCK_SIZE);
    print("capacity: {}\n",heap.capacity * HEAP_BLOCK_SIZE);
    print("free: {}\n",usable_blocks(heap) * HEAP_BLOCK_SIZE);

    putchar('\n');
}

// internal function to add node back to free list
// NOTE: null checking must be done by higher level functions
func free_heap_node(heap: Heap@, insert: HeapNode@)
{
    cur := heap.free_list;

    // handle insertion at start
    if(!cur || insert < cur)
    {
        heap.free_list = insert;

        // attempt to collapse with old first
        if((insert + insert.blocks) == cur)
        {
            insert.blocks += cur.blocks;
            insert.next = cur.next;
        }

        else
        {
            insert.next = cur;
        }

        return;
    }


    // scan for correct insertion location
    // i.e insert > cur && insert < next
    while(cur.next != NULL && !(insert > cur && insert < cur.next))
    {
        cur = cur.next;
    }
    
    // at this point cur contains the lower bound
    // and cur.next contains the upper bound
    // insert is in the middle

    next := cur.next;

    // attempt to collapse upper
    if((insert + insert.blocks) == next)
    {
        insert.blocks += next.blocks;
        insert.next = next;
    }
    
    // cant collapse insert . next
    else
    {
        insert.next = cur.next;
    }

    // attempt to collapse lower
    if((cur + cur.blocks) == insert)
    {
        cur.blocks += insert.blocks;
        cur.next = insert.next;
    }

    // cant collapse cur . insert
    else
    {
        cur.next = insert;
    }
}



func free_heap(heap : Heap@, ptr : byte@@)
{
    if(!ptr)
    {
        return;
    }

    // block info is behind the buffer
    insert := cast(HeapNode@,@ptr) - 1;

    // set our ptr to null
    @ptr = NULL;

    // track memory reclaim
    heap.used -= insert.blocks;

    // actually add it back to the free list
    free_heap_node(heap,insert);
}

func request_buffer(heap : Heap@, size : u64) bool
{
    ptr := os_req_mem(size);

    if(ptr == cast(byte@,OS_INVALID_PTR))
    {
        return false;
    }

    add_buffer(heap,ptr,size);
    return true;
}

func alloc_heap(heap : Heap@, count : u32, size : u32) byte@
{
    bytes := count * size;

    // TODO: this overstimates block aligned data
    // we are just gonna ignore this for now
    req_blocks := (bytes / HEAP_BLOCK_SIZE) + 2;

    // attempt to find a block big enough for allocation?
    cur := heap.free_list;
    prev := cur;

    while(cur)
    {
        if(cur.blocks >= req_blocks)
        {
            // exact size just skip over
            if(cur.blocks == req_blocks)
            {
                prev.next = cur.next;
            }

            // fragment the block
            else
            {
                // cur block gets remaining
                remaining_blocks := cur.blocks - req_blocks;
                cur.blocks -= req_blocks;


                // new block contains the requested allocation
                cur += remaining_blocks;
                cur.blocks = req_blocks;
            }
            
            // mark heap usage
            heap.used += cur.blocks;

            // data is after buffer
            return cast(byte@,(cur + 1));
        }

        prev = cur;
        cur = cur.next;
    }

    req := max_u64(req_blocks * HEAP_BLOCK_SIZE,HEAP_DEFAULT_ALLOC_SIZE);

    // out of memory try get some more
    if(request_buffer(heap,req))
    {
        return alloc_heap(heap,count,size);
    }

    // cannot aquire any more memory we are out
    return NULL;
}

func alloc_heap_panic(heap : Heap@, count : u32, size : u32) byte@
{
    ptr := alloc_heap(heap,count,size);

    if(!ptr)
    {
        crash_and_burn("out of memory for heap alloc: {}\n",size);
    }

    return ptr;
}

func add_buffer(heap : Heap@, ptr : byte@, size : u64)
{
    if(!ptr)
    {
        return;
    }

    // NOTE: we need a block to actually store it
    blocks := (size / HEAP_BLOCK_SIZE);

    node := cast(HeapNode@,ptr);
    node.blocks = blocks;

    // new memory added
    heap.capacity += blocks;

    // directly pass new block
    free_heap_node(heap,node);  
}

func make_heap(buf : byte[]) Heap
{
    heap : Heap;
    add_buffer(&heap,buf.data,buf.len);

    return heap;
}